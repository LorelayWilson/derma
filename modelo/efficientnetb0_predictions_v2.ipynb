{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db708d31",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes Dermatológicas con EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599721d4",
   "metadata": {},
   "source": [
    "## 1. IMPORTACIÓN DE LIBRERÍAS\n",
    "Importamos las librerías necesarias para el procesamiento de datos, construcción y entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf93f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f00d67",
   "metadata": {},
   "source": [
    "## 2. Configuración de parámetros y recursos\n",
    "Configuramos los parámetros principales y verificamos la disponibilidad de GPU para acelerar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e552a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# Parámetros\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "seed = 123\n",
    "train_dir = '../dataset/multi-6/train'\n",
    "test_dir = '../dataset/multi-6/test'\n",
    "model_path = 'efficientnetb0_derma_v4.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850c7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30901 files belonging to 6 classes.\n",
      "Using 24721 files for training.\n",
      "Found 30901 files belonging to 6 classes.\n",
      "Using 6180 files for validation.\n",
      "Clases: ['Acne', 'Benign', 'Eczema', 'Infectious', 'Malign', 'Pigmentation']\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [0 1 3 1 1 3 0 4 2 2 1 3 1 1 5 1 3 4 1 1 1 3 1 1 1 1 2 1 2 3 1 0]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [0 1 5 1 1 1 4 3 1 0 3 1 4 1 3 4 4 1 2 1 5 4 4 4 3 1 2 0 4 1 1 4]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [1 0 0 4 1 3 1 4 1 3 3 4 5 4 3 4 2 4 1 4 3 4 4 1 4 4 1 3 3 3 1 1]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [1 3 1 1 1 1 1 1 4 0 3 4 1 2 3 1 1 5 2 1 4 2 3 3 4 4 2 2 1 1 1 2]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [2 4 1 1 2 3 3 3 4 3 1 0 1 1 3 5 3 5 2 4 2 1 3 1 1 0 0 4 3 4 1 0]\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "# Obtener número de clases\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Clases:\", class_names)\n",
    "\n",
    "#Imprimir dataset\n",
    "for x, y in train_ds.take(5):\n",
    "    print(\"Imagen shape:\", x.shape)\n",
    "    print(\"Etiqueta:\", y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89135ed2",
   "metadata": {},
   "source": [
    "## Función de perdida personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0e5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.  1.  1.  1.  1.  1.]\n",
      " [ 1.  0.  1.  1.  1.  1.]\n",
      " [ 5.  5.  0.  1.  1.  5.]\n",
      " [ 5.  5.  1.  0.  1.  5.]\n",
      " [10. 10.  5.  5.  0. 10.]\n",
      " [ 1.  1.  1.  1.  1.  0.]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# PENALIZACIÓN EN CLASES CON MAYOR RIESGO\n",
    "# ----------------------------\n",
    "\n",
    "high_danger = {4} #Malign\n",
    "\n",
    "moderate_danger = {2, 3} #Eczema, Infectious\n",
    "\n",
    "low_danger = set(range(num_classes)) - high_danger - moderate_danger  #Benign, pigmentation, acne\n",
    "\n",
    "cost_matrix = tf.ones([num_classes, num_classes])           # baseline cost = 1\n",
    "\n",
    "cost_matrix = tf.where(tf.eye(num_classes) == 1, 0., cost_matrix)     # zero on the diagonal\n",
    "\n",
    "# Penalizes False Negatives for the high and moderate danger\n",
    "\n",
    "for high in high_danger:\n",
    "    for low in low_danger:\n",
    "        cost_matrix = tf.tensor_scatter_nd_update(cost_matrix,\n",
    "                                        indices=[[high, low]],\n",
    "                                        updates=[10.0]) \n",
    "        \n",
    "    for mid in moderate_danger:\n",
    "        cost_matrix = tf.tensor_scatter_nd_update(cost_matrix,\n",
    "                                        indices=[[high, mid]],\n",
    "                                        updates=[5.0]) \n",
    "        \n",
    "for mid in moderate_danger:\n",
    "    for low in low_danger:\n",
    "        cost_matrix = tf.tensor_scatter_nd_update(cost_matrix,\n",
    "                                        indices=[[mid, low]],\n",
    "                                        updates=[5.0])\n",
    "        \n",
    "print(cost_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40d9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_matrix_sparse_categorical_crossentropy_loss(\n",
    "        y_true, y_pred, alpha=1.0):\n",
    "\n",
    "    num_classes = cost_matrix.shape[0]\n",
    "\n",
    "    # 1.  Sparse → one‑hot           (B, C)\n",
    "    y_true = tf.one_hot(tf.cast(tf.reshape(y_true, [-1]), tf.int32),\n",
    "                        depth=num_classes)\n",
    "\n",
    "    # 2.  Expected per‑class cost\n",
    "    row_cost = tf.matmul(y_true, cost_matrix)      # or use the expand‑squeeze variant\n",
    "\n",
    "    # 3.  Expected misclassification cost for each example\n",
    "    exp_cost = tf.reduce_sum(row_cost * y_pred, axis=-1)\n",
    "\n",
    "    # 4.  Standard cross‑entropy\n",
    "    ce = tf.keras.losses.categorical_crossentropy(\n",
    "            y_true, tf.nn.softmax(y_pred))\n",
    "\n",
    "    return ce + alpha * exp_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea61da9",
   "metadata": {},
   "source": [
    "## 8. Evaluación y visualización de resultados\n",
    "Evaluamos el modelo en el conjunto de test, mostramos el reporte de clasificación y la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd39bb54",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar modelo entrenado\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#model = tf.keras.models.load_model(model_path)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcost_matrix_sparse_categorical_crossentropy_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_matrix_sparse_categorical_crossentropy_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names)\n\u001b[0;32m      7\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_ds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar modelo entrenado\n",
    "#model = tf.keras.models.load_model(model_path)\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'cost_matrix_sparse_categorical_crossentropy_loss': cost_matrix_sparse_categorical_crossentropy_loss})\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "y_pred_probs = model.predict(val_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for x, y in val_ds])\n",
    "\n",
    "print(\"\\n🧾 Clasification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082935d",
   "metadata": {},
   "source": [
    "## Las 3 clases más probables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f346bfc-ef9d-4f5f-8fb8-ff318831cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Definir el nivel de gravedad de cada clase\n",
    "gravedad = {\n",
    "    0: 0,  # Acne\n",
    "    1: 0,  # Benign\n",
    "    2: 1,  # Eczema\n",
    "    3: 1,  # Infectious\n",
    "    4: 2,  # Malign\n",
    "    5: 0   # Pigmentation\n",
    "}\n",
    "\n",
    "top_k = 4  # Considerar las 4 clases más probables\n",
    "num_imgs = 50  # Primeras 10 imágenes\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for x, y in val_ds])\n",
    "\n",
    "for i in range(num_imgs):\n",
    "    probs = y_pred_probs[i]\n",
    "    real_idx = y_true[i]\n",
    "    top_indices = np.argsort(probs)[-top_k:][::-1]\n",
    "    idx1 = top_indices[0]\n",
    "    conf1 = probs[idx1]\n",
    "    pred_idx = idx1\n",
    "    motivo = \"\"\n",
    "    diferencia_elegida = 0.0\n",
    "    \n",
    "    # Buscar entre las top_k si hay alguna más grave y cercana en confianza\n",
    "    for idx in top_indices[1:]:\n",
    "        conf = probs[idx]\n",
    "        diff = conf1 - conf\n",
    "        if (diff < 0.10) and (gravedad[idx] > gravedad[pred_idx]):\n",
    "            pred_idx = idx\n",
    "            motivo = f\"<span style='color:orange'>*Se elige {class_names[idx]} por mayor gravedad y confianza cercana*</span>\"\n",
    "            diferencia_elegida = diff\n",
    "\n",
    "    color = \"green\" if pred_idx == real_idx else \"red\"\n",
    "\n",
    "    html = f\"<b>Imagen {i+1}:</b><br>\"\n",
    "    for j, idx in enumerate(top_indices):\n",
    "        diff = conf1 - probs[idx]\n",
    "        if j == 0:\n",
    "            html += f\"{j+1}ª: {class_names[idx]}: {probs[idx]*100:.2f}%<br>\"\n",
    "        else:\n",
    "            html += f\"{j+1}ª: {class_names[idx]}: {probs[idx]*100:.2f}% (diferencia: {diff*100:.2f}%)<br>\"\n",
    "    if motivo:\n",
    "        html += motivo + f\" (diferencia: {diferencia_elegida*100:.2f}%)<br>\"\n",
    "    html += f\"<b>Predicción final:</b> <span style='color:{color}'>{class_names[pred_idx]}</span><br>\"\n",
    "    html += f\"<b>Real:</b> {class_names[real_idx]}\"\n",
    "    html += \"<hr>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b552e-2624-4586-b37d-34552f3b189c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356a74b-d5b2-4cd5-9e99-65fef761c760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
