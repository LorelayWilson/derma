{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db708d31",
   "metadata": {},
   "source": [
    "# ClasificaciÃ³n de ImÃ¡genes DermatolÃ³gicas con EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599721d4",
   "metadata": {},
   "source": [
    "## 1. IMPORTACIÃ“N DE LIBRERÃAS\n",
    "Importamos las librerÃ­as necesarias para el procesamiento de datos, construcciÃ³n y entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf93f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f00d67",
   "metadata": {},
   "source": [
    "## 2. ConfiguraciÃ³n de parÃ¡metros y recursos\n",
    "Configuramos los parÃ¡metros principales y verificamos la disponibilidad de GPU para acelerar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e552a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# ParÃ¡metros\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "seed = 123\n",
    "train_dir = '../dataset/multi-6/train'\n",
    "test_dir = '../dataset/multi-6/test'\n",
    "model_path = 'efficientnetb0_derma_v4.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850c7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30901 files belonging to 6 classes.\n",
      "Using 24721 files for training.\n",
      "Found 30901 files belonging to 6 classes.\n",
      "Using 6180 files for validation.\n",
      "Clases: ['Acne', 'Benign', 'Eczema', 'Infectious', 'Malign', 'Pigmentation']\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [0 1 3 1 1 3 0 4 2 2 1 3 1 1 5 1 3 4 1 1 1 3 1 1 1 1 2 1 2 3 1 0]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [0 1 5 1 1 1 4 3 1 0 3 1 4 1 3 4 4 1 2 1 5 4 4 4 3 1 2 0 4 1 1 4]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [1 0 0 4 1 3 1 4 1 3 3 4 5 4 3 4 2 4 1 4 3 4 4 1 4 4 1 3 3 3 1 1]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [1 3 1 1 1 1 1 1 4 0 3 4 1 2 3 1 1 5 2 1 4 2 3 3 4 4 2 2 1 1 1 2]\n",
      "Imagen shape: (32, 224, 224, 3)\n",
      "Etiqueta: [2 4 1 1 2 3 3 3 4 3 1 0 1 1 3 5 3 5 2 4 2 1 3 1 1 0 0 4 3 4 1 0]\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "# Obtener nÃºmero de clases\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Clases:\", class_names)\n",
    "\n",
    "#Imprimir dataset\n",
    "for x, y in train_ds.take(5):\n",
    "    print(\"Imagen shape:\", x.shape)\n",
    "    print(\"Etiqueta:\", y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89135ed2",
   "metadata": {},
   "source": [
    "## FunciÃ³n de perdida personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0e5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.  1.  1.  1.  1.  1.]\n",
      " [ 1.  0.  1.  1.  1.  1.]\n",
      " [ 5.  5.  0.  1.  1.  5.]\n",
      " [ 5.  5.  1.  0.  1.  5.]\n",
      " [10. 10.  5.  5.  0. 10.]\n",
      " [ 1.  1.  1.  1.  1.  0.]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# PENALIZACIÃ“N EN CLASES CON MAYOR RIESGO\n",
    "# ----------------------------\n",
    "\n",
    "high_danger = {4} #Malign\n",
    "\n",
    "moderate_danger = {2, 3} #Eczema, Infectious\n",
    "\n",
    "low_danger = set(range(num_classes)) - high_danger - moderate_danger  #Benign, pigmentation, acne\n",
    "\n",
    "cost_matrix = tf.ones([num_classes, num_classes])           # baseline cost = 1\n",
    "\n",
    "cost_matrix = tf.where(tf.eye(num_classes) == 1, 0., cost_matrix)     # zero on the diagonal\n",
    "\n",
    "# Penalizes False Negatives for the high and moderate danger\n",
    "\n",
    "for high in high_danger:\n",
    "    for low in low_danger:\n",
    "        cost_matrix = tf.tensor_scatter_nd_update(cost_matrix,\n",
    "                                        indices=[[high, low]],\n",
    "                                        updates=[10.0]) \n",
    "        \n",
    "    for mid in moderate_danger:\n",
    "        cost_matrix = tf.tensor_scatter_nd_update(cost_matrix,\n",
    "                                        indices=[[high, mid]],\n",
    "                                        updates=[5.0]) \n",
    "        \n",
    "for mid in moderate_danger:\n",
    "    for low in low_danger:\n",
    "        cost_matrix = tf.tensor_scatter_nd_update(cost_matrix,\n",
    "                                        indices=[[mid, low]],\n",
    "                                        updates=[5.0])\n",
    "        \n",
    "print(cost_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40d9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_matrix_sparse_categorical_crossentropy_loss(\n",
    "        y_true, y_pred, alpha=1.0):\n",
    "\n",
    "    num_classes = cost_matrix.shape[0]\n",
    "\n",
    "    # 1.  Sparse â†’ oneâ€‘hot           (B, C)\n",
    "    y_true = tf.one_hot(tf.cast(tf.reshape(y_true, [-1]), tf.int32),\n",
    "                        depth=num_classes)\n",
    "\n",
    "    # 2.  Expected perâ€‘class cost\n",
    "    row_cost = tf.matmul(y_true, cost_matrix)      # or use the expandâ€‘squeeze variant\n",
    "\n",
    "    # 3.  Expected misclassification cost for each example\n",
    "    exp_cost = tf.reduce_sum(row_cost * y_pred, axis=-1)\n",
    "\n",
    "    # 4.  Standard crossâ€‘entropy\n",
    "    ce = tf.keras.losses.categorical_crossentropy(\n",
    "            y_true, tf.nn.softmax(y_pred))\n",
    "\n",
    "    return ce + alpha * exp_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea61da9",
   "metadata": {},
   "source": [
    "## 8. EvaluaciÃ³n y visualizaciÃ³n de resultados\n",
    "Evaluamos el modelo en el conjunto de test, mostramos el reporte de clasificaciÃ³n y la matriz de confusiÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd39bb54",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar modelo entrenado\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#model = tf.keras.models.load_model(model_path)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcost_matrix_sparse_categorical_crossentropy_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_matrix_sparse_categorical_crossentropy_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names)\n\u001b[0;32m      7\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_ds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar modelo entrenado\n",
    "#model = tf.keras.models.load_model(model_path)\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'cost_matrix_sparse_categorical_crossentropy_loss': cost_matrix_sparse_categorical_crossentropy_loss})\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "y_pred_probs = model.predict(val_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for x, y in val_ds])\n",
    "\n",
    "print(\"\\nðŸ§¾ Clasification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('PredicciÃ³n')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de ConfusiÃ³n')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082935d",
   "metadata": {},
   "source": [
    "## Las 3 clases mÃ¡s probables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f346bfc-ef9d-4f5f-8fb8-ff318831cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Definir el nivel de gravedad de cada clase\n",
    "gravedad = {\n",
    "    0: 0,  # Acne\n",
    "    1: 0,  # Benign\n",
    "    2: 1,  # Eczema\n",
    "    3: 1,  # Infectious\n",
    "    4: 2,  # Malign\n",
    "    5: 0   # Pigmentation\n",
    "}\n",
    "\n",
    "top_k = 4  # Considerar las 4 clases mÃ¡s probables\n",
    "num_imgs = 50  # Primeras 10 imÃ¡genes\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for x, y in val_ds])\n",
    "\n",
    "for i in range(num_imgs):\n",
    "    probs = y_pred_probs[i]\n",
    "    real_idx = y_true[i]\n",
    "    top_indices = np.argsort(probs)[-top_k:][::-1]\n",
    "    idx1 = top_indices[0]\n",
    "    conf1 = probs[idx1]\n",
    "    pred_idx = idx1\n",
    "    motivo = \"\"\n",
    "    diferencia_elegida = 0.0\n",
    "    \n",
    "    # Buscar entre las top_k si hay alguna mÃ¡s grave y cercana en confianza\n",
    "    for idx in top_indices[1:]:\n",
    "        conf = probs[idx]\n",
    "        diff = conf1 - conf\n",
    "        if (diff < 0.10) and (gravedad[idx] > gravedad[pred_idx]):\n",
    "            pred_idx = idx\n",
    "            motivo = f\"<span style='color:orange'>*Se elige {class_names[idx]} por mayor gravedad y confianza cercana*</span>\"\n",
    "            diferencia_elegida = diff\n",
    "\n",
    "    color = \"green\" if pred_idx == real_idx else \"red\"\n",
    "\n",
    "    html = f\"<b>Imagen {i+1}:</b><br>\"\n",
    "    for j, idx in enumerate(top_indices):\n",
    "        diff = conf1 - probs[idx]\n",
    "        if j == 0:\n",
    "            html += f\"{j+1}Âª: {class_names[idx]}: {probs[idx]*100:.2f}%<br>\"\n",
    "        else:\n",
    "            html += f\"{j+1}Âª: {class_names[idx]}: {probs[idx]*100:.2f}% (diferencia: {diff*100:.2f}%)<br>\"\n",
    "    if motivo:\n",
    "        html += motivo + f\" (diferencia: {diferencia_elegida*100:.2f}%)<br>\"\n",
    "    html += f\"<b>PredicciÃ³n final:</b> <span style='color:{color}'>{class_names[pred_idx]}</span><br>\"\n",
    "    html += f\"<b>Real:</b> {class_names[real_idx]}\"\n",
    "    html += \"<hr>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b552e-2624-4586-b37d-34552f3b189c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356a74b-d5b2-4cd5-9e99-65fef761c760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
